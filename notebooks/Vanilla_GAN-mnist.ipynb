{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.backends:backend module://ipykernel.pylab.backend_inline version unknown\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import gluon, autograd, nd\n",
    "from mxnet.gluon import nn, utils\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import cv2\n",
    "import os, sys, tarfile, time, logging\n",
    "\n",
    "stamp =  datetime.now().strftime('%Y_%m_%d-%H_%M')\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  visualize(img_arr):\n",
    "    plt.imshow(img_arr)\n",
    "    plt.axis('off')\n",
    "    \n",
    "\n",
    "def facc(label, pred):\n",
    "    pred = pred.ravel()\n",
    "    label = label.ravel()\n",
    "    #print('aaaaa = {}'.format(((pred > 0.5) == label)*1.))\n",
    "    corr = ((pred > 0.5) == label)*1.\n",
    "    #print('corr = {}'.format(corr.mean()))\n",
    "    return (((pred > 0.5) == label)*1.).mean()\n",
    "metric = mx.metric.CustomMetric(facc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "latent_z_size = 100\n",
    "\n",
    "data_path = 'mnist'\n",
    "context = mx.gpu()\n",
    "\n",
    "epochs = 200\n",
    "disc_study_rate = 1\n",
    "log_freq = 1\n",
    "\n",
    "lr = .0002\n",
    "beta1 = 0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:train-labels-idx1-ubyte.gz exists, skipping download\n",
      "/opt/venv/lib/python3.6/site-packages/mxnet/test_utils.py:1431: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  label = np.fromstring(flbl.read(), dtype=np.int8)\n",
      "INFO:root:train-images-idx3-ubyte.gz exists, skipping download\n",
      "/opt/venv/lib/python3.6/site-packages/mxnet/test_utils.py:1434: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  image = np.fromstring(fimg.read(), dtype=np.uint8).reshape(len(label), rows, cols)\n",
      "INFO:root:t10k-labels-idx1-ubyte.gz exists, skipping download\n",
      "INFO:root:t10k-images-idx3-ubyte.gz exists, skipping download\n"
     ]
    }
   ],
   "source": [
    "# Fixing the random seed\n",
    "#mx.random.seed(42)\n",
    "mnist = mx.test_utils.get_mnist()\n",
    "\n",
    "\n",
    "### 28 * 28 image iterator\n",
    "t = np.array([(x-0.5)*2 for x in mnist['train_data']])\n",
    "train_data = mx.io.NDArrayIter(t, mnist['train_label'], batch_size, shuffle=True, last_batch_handle = 'discard')\n",
    "\n",
    "### Print 28 * 28 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.font_manager:findfont: Matching :family=NanumGothicCoding:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to NanumGothicCoding ('/usr/share/fonts/truetype/nanum/NanumGothic_Coding.ttf') with score of 0.050000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlAAAADGCAYAAAAdQr4yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADU9JREFUeJzt3WuQluV5B/B3d4FdVhEPaJSgHORsjSiooE4UrbEKapIxKWho7ARkKspUDJn2g0eciUmIJ0iUrMF0aNQQJtYoWCe1yXQGsOABpWiWoICgeGBdI3ERYXf7JZ0Jea+32Wt9l2Xh9/v434f7uT+8hz/PvNfcFa2trQUAANqusrM3AADQ1ShQAABJChQAQJICBQCQpEABACQpUAAASQoUAECSAgUAkKRAAQAkKVAAAEndOvoGF1Z+xVkx7Fd+1fLzis68v/cE+xvvCdhbW94TnkABACQpUAAASQoUAECSAgUAkKRAAQAkKVAAAEkKFABAkgIFAJCkQAEAJClQAABJChQAQJICBQCQpEABACQpUAAASQoUAECSAgUAkKRAAQAkKVAAAEkKFABAkgIFAJCkQAEAJClQAABJ3Tp7AwD/p2HquDBvrqkoyj449ZPw2o0XPxjmX9t0Xpive3hkmB+17uMwr/r1C2EOHFw8gQIASFKgAACSFCgAgCQFCgAgyY/IgU+tslevMN89ekiYd7v5nTBfNmRumB9RWdPmvexujfOH+j8T/+Gf43zxH44J89temBjmQ254O8ybtzeEeeuePfF+gC7BEygAgCQFCgAgSYECAEhSoAAAkhQoAIAkU3hdXNXIoWH+6jcPC/O1X5gf5j0reoT56c9PDvOjL6tvw+7oqlrOGRXmb55bG+afPX9LmD81vC5557ZP23W0rx76bpx/fmH8D56P4xGPzgjzQb+Ij4qpWL7mL+4NuoKqYYPD/NVvHhHml54av/bv67u6KJv51unhtfVjdrdxd5+eJ1AAAEkKFABAkgIFAJCkQAEAJClQAABJpvC6iG03nhXmj838bpg/1DguzM+6a1aYN322JcxfnfSDML/09KvDvHX12jCnayk1bffStfM69L6//Ciezvm4tXuH3fP8npvDvE9Vz7KsX+o9NKrh+jDvt7wst4V22z49/v54f0x8fmPp6bklZdvTn1v1bv8w713Y0GH3/HOeQAEAJClQAABJChQAQJICBQCQpEABACSZwutElTXxuV8bbj21KFt51ffCa894/MYwHz5nY5gf986KMG8ef1qYFybFceUHH8XrxJdzgBi/9ith/uuTfx7m//VxfMbiNU9MC/Nht8VnLDY3NrZhd+1zx81/G+YvT+/YiUMot+zZc/PHLwrzCbUdex5jqXPslteNCfM+C1YWZfty2q4UT6AAAJIUKACAJAUKACBJgQIASFKgAACSTOF1oi3/GE++vTKlePrnlAdmh9cOmVNiqi65lzcuqg7zlbuq4vV/93ryDnQlA3/8Wpi3LihxFtbAq8O8sumTMB+87tkw74wpzs+s3h3/YXp51t+6Z2eY12xvLc8N4I/evzvON46qS60zds0VYb778aNT60TTc39cKb6+UOr6/ZMnUAAASQoUAECSAgUAkKRAAQAkKVAAAEmm8PaBbscdG+YLp98b5mevubIoO+HO58Jrs3M8VSOHhvktX1qcXIkD2Z6338n9g+0NYdwZU3UV1fFEaf19nwvzu89/pCO3U5j4wLfCvN+P4glaaIv1dcXnyc0fGp9tV2qqrmZefEZe76dWl7hr558/tz/xBAoAIEmBAgBIUqAAAJIUKACAJAUKACDJFF4ZVXTvEeaXPrM2zFc0DQnzo6fuKMr27I7PFMs6/idbwnzSoe+F+eAn4wPBhhZKTWnAvtH05TPDvGbGW2G+fvgDHbmdwiM7PhPmAx59M8zjUwVhb9unjwvzjRPuL8pmvlU8mVcoFApH3hCv3Vzvc/zT8AQKACBJgQIASFKgAACSFCgAgCQFCgAgyRReGb07dXSYf6P3yjC/YMY/hHnPbas+/V5mnBXmj/W9J8zf2BNP+Y38dnwmmgki9qVts4pfzytm3RVeW13RvUP3MvxnM8J80GO7wrxy44sduR0OcGdPi89BjTzx4qgwP/K8+Ku+16D4LLzqkmfh8ac8gQIASFKgAACSFCgAgCQFCgAgSYECAEgyhVdG/SZtDPMf/X5AmNc+9VKYtybu2W1g/zC//8Z5Yd69oirML3jixjAfsum/E7uBtmk5J54W2vjFmjBfM6l44q5c03bbm3eG+ZfXfT3Mhy78IMxb/ue3ZdkPB6ffLxsc5vf1XRLm0bl31dvir/TbZz8U5nPWTwzz2tfjvTTXbwjzg5UnUAAASQoUAECSAgUAkKRAAQAk+RF5GT02eFmYD3s4PvrhxF3xES+Rqj5HhfnAxW+H+ejqeJ3h/zk1zm+NfxzY/Je3BoWK6vgF13rK0DCfVPfvYf53h71Z4g7FPxjf1bo7vHJHS+6gofP+ZXaYD7gpfn+2pFbnYLXr4uIfeRcKhcLn5qwJ81I/Fh/+YHzk16CfvleU9a+PX7PXHTclzDdOqAvzSwpXhDl78wQKACBJgQIASFKgAACSFCgAgCQFCgAgyRReO3x0xZkl/vJCmA76t/ioiFJ2TBpblH1rzr+G115a+2GYL9pxXJgPm7U1zJu3N7Rxd1Bswx2nhfmrV84vy/rXbDmvKFv1+Mnhtf2+vSK19oBC26dhoa3eHhd/vf6m7+owLzVt1//m+PVpQrrzeQIFAJCkQAEAJClQAABJChQAQJICBQCQZAqvHWq37QrzhpZ42u7yumfC/MQe74b5mdXFU0Tvt8QncFVVHBrm33kkPsvohPdyE0ocnKoO7x3mu08eFOa3Xba4LPedsunCMN8x5bCirN/rXsvsv0pNz13y0/izudQ5duUwf/yiDlv7YOYJFABAkgIFAJCkQAEAJClQAABJChQAQJIpvHaoWL4mzC+cOzvMx0x+OcwXvjcuzKuWHFWU3XLTQ+G1N22N1xgw96Uwj2f5YG+bZpwU5i9dO68s639901+H+YeXxdc3N2wqy32hszXXb+iwtTffHn8fTKiNv7MGLp0W5kPr4/P62JsnUAAASQoUAECSAgUAkKRAAQAkKVAAAEmm8Mro2Hvjs7m23htf36fid2G+fmGvouycmsbw2u/fEp9N1v2j5+Obwp864+QwvvPqn5Rl+cmvXxTmO7/WM8ybG7aU5b4ZVSOHhnnzYTVhvvO2HWE+/tj1ZdnP1p1HFGWv3T4ivLZ6mWmp9to+PZ5Y67Og486kK6do4u77V8bT2kub4tfyiLnx90pz+7d1UPEECgAgSYECAEhSoAAAkhQoAIAkBQoAIMkUXidq+uIZYb7+Cz8syoYtuSG8dsh/PFvWPXFgajn31DC/asHSML+4Np40y3px8/FhfvxfxR891ZvbPoW34e6xYd5a1drmNQqFQuHOv3k0zL90yPupdcplzHevL8qOXRZP+NJ+z99yf5jPnHZ6mC+vGxPm5ZraW18X33fjhLoS/6L4fLuxa64Irzwy/vro0HP5DgaeQAEAJClQAABJChQAQJICBQCQpEABACSZwutEc+bG0xXP7KwtyobfWh9e68wi2qL7y5vC/I4XLgnzq879cVnu+9vxD4b5urP3hPn6u49p89qXHxKfA1fZxf9f2NQ3N0VI+5Q6H+6+vvHraunstWE+5/KJYX7T0CfDfELtxyV2VDxVVygUCjPfiqfzNlzVvyjrXWKqzvdEx+janzQAAJ1AgQIASFKgAACSFCgAgCQFCgAgyRTePrDngtFhPqY6PsfuzB/MKsr6NToLi/ZrbmwM8yFTd4X52J9NDvNnT3ukLPs5qUf80XNSj8z5c13j/38jHr4uzKsbK8J88D3F01gtZd0RhUKhcPP3/j7Mn572XJiXms6bMGpJmJc6l+66N48I8/6/CONC9VPxfQsF59h1tq7xCQQAsB9RoAAAkhQoAIAkBQoAIEmBAgBIMoVXRpWHHBLmn79rZZg/3RSf+9X//nVFmbOM6AgtTU1h3m3xUWE+5cgLw3zRgF+VbU8dZWlT7zC/Z2Y8cVj73Kay3PfEhlXxH1rid7WJu32jz4L4c7l+QXz9RYVRqfV7l5iSi1+FdEWeQAEAJClQAABJChQAQJICBQCQpEABACSZwiujN2aeEua/7DMvzCd89RthXvFB8VlYsC8dviieUPrwyfgcrzMmXx/mfzihNcxfmTI/tZ8Rv5lalPVa3jO1xuGvfRLm1U/HZ42ZfAX+P55AAQAkKVAAAEkKFABAkgIFAJDkR+RldO2UJ8L8Ow0nhXnlqlfCPP7ZLXS+5sbGMD/mhyvivMQ6E/9pdOq+JxZeTF0P0NE8gQIASFKgAACSFCgAgCQFCgAgSYECAEgyhVdGo2o2h/k1D14X5v12x5NLAMD+zRMoAIAkBQoAIEmBAgBIUqAAAJIUKACAJFN4ZXT7oNPCvF/BtB0AHEg8gQIASFKgAACSFCgAgCQFCgAgSYECAEhSoAAAkhQoAIAkBQoAIEmBAgBIUqAAAJIUKACApIrW1tbO3gMAQJfiCRQAQJICBQCQpEABACQpUAAASQoUAECSAgUAkKRAAQAkKVAAAEkKFABAkgIFAJCkQAEAJClQAABJChQAQJICBQCQpEABACQpUAAASQoUAECSAgUAkKRAAQAkKVAAAEkKFABAkgIFAJD0v73FfvfnpdOAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i, j in enumerate(np.random.choice(range(100), 3)):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    print(mnist['train_data'][j + 10][0].shape)\n",
    "    visualize(mnist['train_data'][j + 10][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 64\n",
    "class Gen(gluon.HybridBlock):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Gen, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.dense1 = nn.Dense(128)\n",
    "            self.dense2 = nn.Dense(256)\n",
    "            self.dense3 = nn.Dense(784)\n",
    "            self.bn1 = nn.BatchNorm()\n",
    "            self.bn2 = nn.BatchNorm()\n",
    "            \n",
    "    def hybrid_forward(self, F, x):\n",
    "        x = self.dense1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = nd.relu(x)\n",
    "        #print('x1.shape = {}'.format(x.shape))\n",
    "        x = self.dense2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = nd.relu(x)\n",
    "        x = self.dense3(x)\n",
    "        x = nd.tanh(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the generator\n",
    "#nc = 1\n",
    "#ngf = 32\n",
    "#gen = nn.Sequential()\n",
    "#with gen.name_scope():\n",
    "#    # input is Z, going into a convolution\n",
    "#    gen.add(nn.Conv2DTranspose(ngf * 8, 4, 1, 0, use_bias=False))\n",
    "#    gen.add(nn.BatchNorm())\n",
    "#    gen.add(nn.Activation('relu'))\n",
    "#    # state size. (ngf*8) x 4 x 4\n",
    "#    gen.add(nn.Conv2DTranspose(ngf * 4, 4, 2, 1, use_bias=False))\n",
    "#    gen.add(nn.BatchNorm())\n",
    "#    gen.add(nn.Activation('relu'))\n",
    "#    # state size. (ngf*4) x 8 x 8\n",
    "#    gen.add(nn.Conv2DTranspose(ngf * 2, 4, 2, 1, use_bias=False))\n",
    "#    gen.add(nn.BatchNorm())\n",
    "#    gen.add(nn.Activation('relu'))\n",
    "#    # state size. (ngf*2) x 16 x 16\n",
    "#    gen.add(nn.Conv2DTranspose(ngf, 4, 2, 1, use_bias=False))\n",
    "#    gen.add(nn.BatchNorm())\n",
    "#    gen.add(nn.Activation('relu'))\n",
    "#    # state size. () x 32 x 32\n",
    "#    gen.add(nn.Conv2DTranspose(nc, 4, 2, 1, use_bias=False))\n",
    "#    gen.add(nn.Activation('sigmoid'))\n",
    "#    # state size. (nc) x 64 x 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE\n",
    "\n",
    "### What I did\n",
    "* Added Batch normalization\n",
    "* Put .2 in LaekyRelu layer\n",
    "\n",
    "\n",
    "### Important\n",
    "* Batch normalization is important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode Collapse Problem\n",
    "\n",
    "* To check if there is model collapse problem I need to print multiple figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Disc(gluon.HybridBlock):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Disc, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.dense1 = nn.Dense(128)\n",
    "            self.dense2 = nn.Dense(64)\n",
    "            self.dense3 = nn.Dense(1)\n",
    "            self.bn1 = nn.BatchNorm()\n",
    "            self.bn2 = nn.BatchNorm()\n",
    "            self.leaky1 = nn.LeakyReLU(.01)\n",
    "            self.leaky2 = nn.LeakyReLU(.01)\n",
    "            \n",
    "    def hybrid_forward(self, F, x):\n",
    "        x = self.dense1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.leaky1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.leaky2(x)\n",
    "        x = self.dense3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-584fff71f77c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#gen = Gen()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdisc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDisc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.02\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.02\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gen' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#gen = Gen()\n",
    "disc = Disc()\n",
    "gen.collect_params().initialize(mx.init.Normal(0.02), ctx = context)\n",
    "disc.collect_params().initialize(mx.init.Normal(0.02), ctx = context)\n",
    "\n",
    "loss = gluon.loss.SigmoidBinaryCrossEntropyLoss()\n",
    "gen_trainer = gluon.Trainer(gen.collect_params(), 'adam', {'learning_rate': lr, 'beta1': beta1})\n",
    "disc_trainer = gluon.Trainer(disc.collect_params(), 'adam', {'learning_rate': lr, 'beta1': beta1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss metric\n",
    "real_label = nd.ones((batch_size,), ctx=context)\n",
    "fake_label = nd.zeros((batch_size,),ctx=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test에서 항상 뽑아볼 수 있는 고정된 z를 사전에 뽑아둡니다.\n",
    "latent_dim = 64\n",
    "fixed_z = nd.random.uniform(shape = (16, latent_dim), ctx = context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE\n",
    "\n",
    "* I added Batch Normalization\n",
    "* Normalize data: -1 < x < 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "iter_loss = dict()\n",
    "iter_loss['disc'] = []\n",
    "iter_loss['gen'] = []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    tic = time.time()\n",
    "    btic = time.time()\n",
    "    train_data.reset()\n",
    "    iter = 0\n",
    "    n_data = 0\n",
    "    for batch in train_data:\n",
    "        # Reshape data\n",
    "        ## Discriminator error\n",
    "        data = batch.data[0].as_in_context(context)\n",
    "        latent_z = nd.random.uniform(0, 1, shape =(batch_size, latent_dim), ctx = context)\n",
    "        \n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        with autograd.record():\n",
    "            #print('data reshape = {}'.format(data.reshape((-1, 28 * 28)).shape))\n",
    "            # real error\n",
    "            out_real = disc(data.reshape((-1, 28 * 28))).reshape((-1, 1))\n",
    "            d_err_real = loss(out_real, real_label)\n",
    "            metric.update([real_label,], [out_real,])\n",
    "            # fake error\n",
    "            fake = gen(latent_z)\n",
    "            #print('fake reshape = {}'.format(fake.shape))\n",
    "            out_fake = disc(fake.detach()).reshape((-1, 1)) # Generator 고정시키기\n",
    "            d_err_fake = loss(out_fake, fake_label)\n",
    "            d_err = d_err_real + d_err_fake\n",
    "            d_err.backward()\n",
    "            metric.update([fake_label,], [out_fake,])\n",
    "            #print('d_err = {}'.format(d_err))\n",
    "        disc_trainer.step(batch_size)\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        with autograd.record():\n",
    "            fake = gen(latent_z)\n",
    "            #print('fake size = {}'.format(fake.shape))\n",
    "            out = disc(fake).reshape((-1, 1))\n",
    "            #print('out size = {}'.format(out.shape))\n",
    "            g_err = loss(out, real_label)\n",
    "            g_err.backward()\n",
    "        gen_trainer.step(batch_size)\n",
    "        n_data += data.shape[0]\n",
    "    \n",
    "        iter += 1\n",
    "        \n",
    "        #if iter % 100 == 0:\n",
    "        #    gen_img = gen(fixed_z[:1, :])\n",
    "        #    print(gen_img.asnumpy().reshape((28, 28)).shape)\n",
    "        #    plt.imshow(gen_img.asnumpy().reshape((28, 28))) #Needs to be in row,col order\n",
    "        #    plt.show()\n",
    "\n",
    "    #save dis/gen loss\n",
    "    if epoch % log_freq == 0:\n",
    "        name, acc = metric.get()\n",
    "        logging.info('speed: {} samples/s'.format(n_data / (time.time() - btic)))\n",
    "        logging.info('discriminator loss = %f, generator loss = %f, binary training acc = %f at epoch %d'\n",
    "                            %(nd.mean(d_err).asscalar(),\n",
    "                            nd.mean(g_err).asscalar(), acc, epoch))\n",
    "        iter_loss['disc'].append(nd.mean(d_err).asscalar())\n",
    "        iter_loss['gen'].append(nd.mean(g_err).asscalar())\n",
    "        gen_img = gen(fixed_z)\n",
    "        plt.figure(figsize=(10,10))\n",
    "        for i in range(8):\n",
    "            plt.subplot(1,8,i+1)\n",
    "            plt.imshow(gen_img[i].asnumpy().reshape((28, 28)), cmap='Greys_r')\n",
    "            plt.axis('off')\n",
    "        plt.show()\n",
    "    name, acc = metric.get()\n",
    "    metric.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        plt.figure(figsize=(10,10))\n",
    "        for i in range(16):\n",
    "            plt.add_subplot(4,4,i+1)\n",
    "            print(i)\n",
    "            #plt.imshow(gen_img[i][0].asnumpy(), cmap='gray')\n",
    "            plt.imshow((gen_img[i][0].asnumpy() +1)*127.5,cmap='gray')\n",
    "            plt.axis('off')\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
